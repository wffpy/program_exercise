' @startuml
' title Sequence Diagram of User login
' actor User as user

' participant "gateway" as gateway
' participant "user-core" as userCore
' database "MySQL" as mysql
' database "Redis" as redis

' autonumber
' user-> gateway:login request，param：username，password
' activate gateway
' gateway-> userCore:forward the login request
' activate userCore
' userCore-> userCore :check the login param
' userCore-> mysql:query user info from mysql by username
' activate mysql
' mysql-> userCore:response with username and password
' deactivate mysql
' userCore->userCore:compare the requested password with the DB's password
' userCore-> userCore: generate an unique token
' userCore--> redis: save the token to redis
' userCore-> gateway: response with the token
' deactivate userCore
' gateway-> user: login success with the token
' deactivate gateway
' @enduml

@startuml
title Sequence Diagram of Model-Building
activate pretrain
pretrain -> pretrain: initialize_megatron
activate  step_2
pretrain -> step_2: setup_model_and_optimizer
activate step_3
step_2 -> step_3: get_model
activate step_4
step_3 -> step_4: model_provider(in pretrain_llamam.py)
activate LLaMAModel
step_4 -> LLaMAModel: (buidl LLaMAModel instance)
activate step_6
LLaMAModel -> step_6: get_language_model
activate step_7
step_6 -> step_7: (build TransformerLanguageModel 实例)
activate step_8
step_7 -> step_8: (build ParallelTransformer 实例)
step_8 -> step_8: _get_num_layers

step_8 -> step_8: 根据layer 数量循环调用build_layer函数
step_8 -> step_7
deactivate step_8
step_7 -> step_6
deactivate step_7
step_6 -> LLaMAModel
deactivate step_6
LLaMAModel -> step_4: return the LLaMAModel instance
deactivate LLaMAModel

step_4 -> step_3
deactivate step_4
step_3 -> step_2
deactivate step_3
step_2 -> pretrain
deactivate step_2
deactivate pretrain
@enduml